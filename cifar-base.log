Script started on 2021-12-13 19:25:17+0800
(base) ]0;root@DESKTOP-VFHBUQ9: /mnt/e/GitHub Repo/LPMroot@DESKTOP-VFHBUQ9:/mnt/e/GitHub Repo/LPM# sh run-cifar-base.sh
save test data time: 2021-12-13 19:25:21
Files already downloaded and verified
test label num [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
save train data time: 2021-12-13 19:25:28
Files already downloaded and verified
train label num [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
load data from pickle time: 2021-12-13 19:25:49
build model time: 2021-12-13 19:25:59
train model time: 2021-12-13 19:25:59
epoch: 0 loss: tensor(419.2149, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:08
epoch: 1 loss: tensor(282.2223, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:17
epoch: 2 loss: tensor(257.2491, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:26
epoch: 3 loss: tensor(207.5441, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:34
epoch: 4 loss: tensor(187.6004, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:43
epoch: 5 loss: tensor(179.4001, grad_fn=<AddBackward0>) time: 2021-12-13 19:26:52
epoch: 6 loss: tensor(176.2323, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:01
epoch: 7 loss: tensor(155.8809, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:09
epoch: 8 loss: tensor(138.6764, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:18
epoch: 9 loss: tensor(127.1226, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:27
epoch: 10 loss: tensor(115.4553, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:35
epoch: 11 loss: tensor(104.0901, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:44
epoch: 12 loss: tensor(95.1742, grad_fn=<AddBackward0>) time: 2021-12-13 19:27:53
epoch: 13 loss: tensor(84.4124, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:02
epoch: 14 loss: tensor(75.0977, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:10
epoch: 15 loss: tensor(67.6185, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:19
epoch: 16 loss: tensor(59.8955, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:28
epoch: 17 loss: tensor(52.9198, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:37
epoch: 18 loss: tensor(46.6489, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:46
epoch: 19 loss: tensor(40.8498, grad_fn=<AddBackward0>) time: 2021-12-13 19:28:54
epoch: 20 loss: tensor(35.4946, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:03
epoch: 21 loss: tensor(31.0737, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:12
epoch: 22 loss: tensor(27.1162, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:21
epoch: 23 loss: tensor(22.9919, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:30
epoch: 24 loss: tensor(20.9288, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:38
epoch: 25 loss: tensor(18.7428, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:47
epoch: 26 loss: tensor(14.9431, grad_fn=<AddBackward0>) time: 2021-12-13 19:29:56
epoch: 27 loss: tensor(15.3749, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:05
epoch: 28 loss: tensor(13.3502, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:14
epoch: 29 loss: tensor(11.8003, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:22
epoch: 30 loss: tensor(11.2183, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:31
epoch: 31 loss: tensor(11.2051, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:40
epoch: 32 loss: tensor(9.5514, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:49
epoch: 33 loss: tensor(11.3145, grad_fn=<AddBackward0>) time: 2021-12-13 19:30:58
epoch: 34 loss: tensor(9.2079, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:07
epoch: 35 loss: tensor(8.5757, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:16
epoch: 36 loss: tensor(8.8350, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:24
epoch: 37 loss: tensor(7.8353, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:33
epoch: 38 loss: tensor(8.1433, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:42
epoch: 39 loss: tensor(8.5202, grad_fn=<AddBackward0>) time: 2021-12-13 19:31:51
epoch: 40 loss: tensor(8.4149, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:00
epoch: 41 loss: tensor(7.8733, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:08
epoch: 42 loss: tensor(8.2113, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:17
epoch: 43 loss: tensor(7.7225, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:26
epoch: 44 loss: tensor(7.5875, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:35
epoch: 45 loss: tensor(9.2258, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:44
epoch: 46 loss: tensor(6.7946, grad_fn=<AddBackward0>) time: 2021-12-13 19:32:52
epoch: 47 loss: tensor(7.8166, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:01
epoch: 48 loss: tensor(6.6892, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:10
epoch: 49 loss: tensor(7.3279, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:19
epoch: 50 loss: tensor(7.3073, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:28
epoch: 51 loss: tensor(6.9609, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:36
epoch: 52 loss: tensor(7.0931, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:45
epoch: 53 loss: tensor(7.5848, grad_fn=<AddBackward0>) time: 2021-12-13 19:33:54
epoch: 54 loss: tensor(6.7513, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:03
epoch: 55 loss: tensor(6.6170, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:12
epoch: 56 loss: tensor(7.4155, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:20
epoch: 57 loss: tensor(7.0841, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:29
epoch: 58 loss: tensor(7.1488, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:38
epoch: 59 loss: tensor(7.2103, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:47
epoch: 60 loss: tensor(5.4855, grad_fn=<AddBackward0>) time: 2021-12-13 19:34:56
epoch: 61 loss: tensor(6.7449, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:04
epoch: 62 loss: tensor(7.1156, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:13
epoch: 63 loss: tensor(6.8604, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:22
epoch: 64 loss: tensor(6.7461, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:31
epoch: 65 loss: tensor(6.4398, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:40
epoch: 66 loss: tensor(6.5462, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:48
epoch: 67 loss: tensor(6.7965, grad_fn=<AddBackward0>) time: 2021-12-13 19:35:57
epoch: 68 loss: tensor(6.7025, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:06
epoch: 69 loss: tensor(6.2009, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:15
epoch: 70 loss: tensor(6.9350, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:24
epoch: 71 loss: tensor(5.6031, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:32
epoch: 72 loss: tensor(6.1832, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:41
epoch: 73 loss: tensor(6.5144, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:50
epoch: 74 loss: tensor(6.2901, grad_fn=<AddBackward0>) time: 2021-12-13 19:36:59
epoch: 75 loss: tensor(6.2810, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:08
epoch: 76 loss: tensor(6.5059, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:16
epoch: 77 loss: tensor(6.0610, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:25
epoch: 78 loss: tensor(6.5704, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:34
epoch: 79 loss: tensor(5.3181, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:43
epoch: 80 loss: tensor(6.3224, grad_fn=<AddBackward0>) time: 2021-12-13 19:37:52
epoch: 81 loss: tensor(5.7953, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:00
epoch: 82 loss: tensor(5.9570, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:09
epoch: 83 loss: tensor(6.1078, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:18
epoch: 84 loss: tensor(6.1642, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:27
epoch: 85 loss: tensor(6.5510, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:36
epoch: 86 loss: tensor(6.7015, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:44
epoch: 87 loss: tensor(5.3359, grad_fn=<AddBackward0>) time: 2021-12-13 19:38:53
epoch: 88 loss: tensor(6.5220, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:02
epoch: 89 loss: tensor(6.1804, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:11
divide current learning rate by 10
epoch: 90 loss: tensor(1.9919, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:20
epoch: 91 loss: tensor(0.4047, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:28
epoch: 92 loss: tensor(0.2773, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:37
epoch: 93 loss: tensor(0.2330, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:46
epoch: 94 loss: tensor(0.2118, grad_fn=<AddBackward0>) time: 2021-12-13 19:39:55
epoch: 95 loss: tensor(0.1932, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:04
epoch: 96 loss: tensor(0.1740, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:12
epoch: 97 loss: tensor(0.1706, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:21
epoch: 98 loss: tensor(0.1610, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:30
epoch: 99 loss: tensor(0.1578, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:39
epoch: 100 loss: tensor(0.1542, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:47
epoch: 101 loss: tensor(0.1525, grad_fn=<AddBackward0>) time: 2021-12-13 19:40:56
epoch: 102 loss: tensor(0.1458, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:05
epoch: 103 loss: tensor(0.1452, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:14
epoch: 104 loss: tensor(0.1461, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:23
epoch: 105 loss: tensor(0.1426, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:31
epoch: 106 loss: tensor(0.1426, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:40
epoch: 107 loss: tensor(0.1457, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:49
epoch: 108 loss: tensor(0.1378, grad_fn=<AddBackward0>) time: 2021-12-13 19:41:58
epoch: 109 loss: tensor(0.1376, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:07
epoch: 110 loss: tensor(0.1423, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:15
epoch: 111 loss: tensor(0.1381, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:24
epoch: 112 loss: tensor(0.1381, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:33
epoch: 113 loss: tensor(0.1413, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:42
epoch: 114 loss: tensor(0.1384, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:51
epoch: 115 loss: tensor(0.1391, grad_fn=<AddBackward0>) time: 2021-12-13 19:42:59
epoch: 116 loss: tensor(0.1414, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:08
epoch: 117 loss: tensor(0.1438, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:17
epoch: 118 loss: tensor(0.1428, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:26
epoch: 119 loss: tensor(0.1417, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:35
epoch: 120 loss: tensor(0.1424, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:43
epoch: 121 loss: tensor(0.1446, grad_fn=<AddBackward0>) time: 2021-12-13 19:43:52
epoch: 122 loss: tensor(0.1428, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:01
epoch: 123 loss: tensor(0.1471, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:10
epoch: 124 loss: tensor(0.1430, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:19
epoch: 125 loss: tensor(0.1459, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:27
epoch: 126 loss: tensor(0.1447, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:36
epoch: 127 loss: tensor(0.1498, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:45
epoch: 128 loss: tensor(0.1489, grad_fn=<AddBackward0>) time: 2021-12-13 19:44:54
epoch: 129 loss: tensor(0.1466, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:03
epoch: 130 loss: tensor(0.1483, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:12
epoch: 131 loss: tensor(0.1481, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:20
epoch: 132 loss: tensor(0.1485, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:29
epoch: 133 loss: tensor(0.1520, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:38
epoch: 134 loss: tensor(0.1511, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:47
epoch: 135 loss: tensor(0.1491, grad_fn=<AddBackward0>) time: 2021-12-13 19:45:55
epoch: 136 loss: tensor(0.1495, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:04
epoch: 137 loss: tensor(0.1532, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:13
epoch: 138 loss: tensor(0.1515, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:22
epoch: 139 loss: tensor(0.1515, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:31
epoch: 140 loss: tensor(0.1548, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:39
epoch: 141 loss: tensor(0.1525, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:48
epoch: 142 loss: tensor(0.1533, grad_fn=<AddBackward0>) time: 2021-12-13 19:46:57
epoch: 143 loss: tensor(0.1547, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:06
epoch: 144 loss: tensor(0.1534, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:15
epoch: 145 loss: tensor(0.1544, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:24
epoch: 146 loss: tensor(0.1551, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:32
epoch: 147 loss: tensor(0.1561, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:41
epoch: 148 loss: tensor(0.1587, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:50
epoch: 149 loss: tensor(0.1576, grad_fn=<AddBackward0>) time: 2021-12-13 19:47:59
epoch: 150 loss: tensor(0.1540, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:08
epoch: 151 loss: tensor(0.1602, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:16
epoch: 152 loss: tensor(0.1553, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:25
epoch: 153 loss: tensor(0.1596, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:34
epoch: 154 loss: tensor(0.1566, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:43
epoch: 155 loss: tensor(0.1574, grad_fn=<AddBackward0>) time: 2021-12-13 19:48:52
epoch: 156 loss: tensor(0.1581, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:00
epoch: 157 loss: tensor(0.1583, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:09
epoch: 158 loss: tensor(0.1565, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:18
epoch: 159 loss: tensor(0.1603, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:27
epoch: 160 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:36
epoch: 161 loss: tensor(0.1611, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:44
epoch: 162 loss: tensor(0.1601, grad_fn=<AddBackward0>) time: 2021-12-13 19:49:53
epoch: 163 loss: tensor(0.1602, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:02
epoch: 164 loss: tensor(0.1609, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:11
epoch: 165 loss: tensor(0.1586, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:20
epoch: 166 loss: tensor(0.1613, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:28
epoch: 167 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:37
epoch: 168 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:46
epoch: 169 loss: tensor(0.1620, grad_fn=<AddBackward0>) time: 2021-12-13 19:50:55
epoch: 170 loss: tensor(0.1643, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:04
epoch: 171 loss: tensor(0.1609, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:12
epoch: 172 loss: tensor(0.1614, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:21
epoch: 173 loss: tensor(0.1647, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:30
epoch: 174 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:39
epoch: 175 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:48
epoch: 176 loss: tensor(0.1611, grad_fn=<AddBackward0>) time: 2021-12-13 19:51:57
epoch: 177 loss: tensor(0.1643, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:05
epoch: 178 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:14
epoch: 179 loss: tensor(0.1620, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:23
divide current learning rate by 10
epoch: 180 loss: tensor(0.1653, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:32
epoch: 181 loss: tensor(0.1622, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:41
epoch: 182 loss: tensor(0.1617, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:49
epoch: 183 loss: tensor(0.1614, grad_fn=<AddBackward0>) time: 2021-12-13 19:52:58
epoch: 184 loss: tensor(0.1617, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:07
epoch: 185 loss: tensor(0.1628, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:16
epoch: 186 loss: tensor(0.1620, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:24
epoch: 187 loss: tensor(0.1631, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:33
epoch: 188 loss: tensor(0.1620, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:42
epoch: 189 loss: tensor(0.1653, grad_fn=<AddBackward0>) time: 2021-12-13 19:53:51
epoch: 190 loss: tensor(0.1626, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:00
epoch: 191 loss: tensor(0.1600, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:08
epoch: 192 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:17
epoch: 193 loss: tensor(0.1616, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:26
epoch: 194 loss: tensor(0.1610, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:35
epoch: 195 loss: tensor(0.1610, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:44
epoch: 196 loss: tensor(0.1611, grad_fn=<AddBackward0>) time: 2021-12-13 19:54:52
epoch: 197 loss: tensor(0.1616, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:01
epoch: 198 loss: tensor(0.1617, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:10
epoch: 199 loss: tensor(0.1609, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:19
epoch: 200 loss: tensor(0.1625, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:28
epoch: 201 loss: tensor(0.1628, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:36
epoch: 202 loss: tensor(0.1612, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:45
epoch: 203 loss: tensor(0.1607, grad_fn=<AddBackward0>) time: 2021-12-13 19:55:54
epoch: 204 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:03
epoch: 205 loss: tensor(0.1623, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:11
epoch: 206 loss: tensor(0.1625, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:20
epoch: 207 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:29
epoch: 208 loss: tensor(0.1609, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:38
epoch: 209 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:47
epoch: 210 loss: tensor(0.1613, grad_fn=<AddBackward0>) time: 2021-12-13 19:56:55
epoch: 211 loss: tensor(0.1623, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:04
epoch: 212 loss: tensor(0.1602, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:13
epoch: 213 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:22
epoch: 214 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:31
epoch: 215 loss: tensor(0.1616, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:39
epoch: 216 loss: tensor(0.1610, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:48
epoch: 217 loss: tensor(0.1646, grad_fn=<AddBackward0>) time: 2021-12-13 19:57:57
epoch: 218 loss: tensor(0.1614, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:06
epoch: 219 loss: tensor(0.1611, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:15
epoch: 220 loss: tensor(0.1610, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:23
epoch: 221 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:32
epoch: 222 loss: tensor(0.1591, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:41
epoch: 223 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:50
epoch: 224 loss: tensor(0.1604, grad_fn=<AddBackward0>) time: 2021-12-13 19:58:58
epoch: 225 loss: tensor(0.1598, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:07
epoch: 226 loss: tensor(0.1588, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:16
epoch: 227 loss: tensor(0.1625, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:25
epoch: 228 loss: tensor(0.1609, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:33
epoch: 229 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:42
epoch: 230 loss: tensor(0.1613, grad_fn=<AddBackward0>) time: 2021-12-13 19:59:51
epoch: 231 loss: tensor(0.1638, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:00
epoch: 232 loss: tensor(0.1620, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:09
epoch: 233 loss: tensor(0.1611, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:17
epoch: 234 loss: tensor(0.1596, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:26
epoch: 235 loss: tensor(0.1621, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:35
epoch: 236 loss: tensor(0.1612, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:44
epoch: 237 loss: tensor(0.1618, grad_fn=<AddBackward0>) time: 2021-12-13 20:00:52
epoch: 238 loss: tensor(0.1615, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:01
epoch: 239 loss: tensor(0.1649, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:10
epoch: 240 loss: tensor(0.1622, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:19
epoch: 241 loss: tensor(0.1618, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:27
epoch: 242 loss: tensor(0.1627, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:36
epoch: 243 loss: tensor(0.1618, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:45
epoch: 244 loss: tensor(0.1623, grad_fn=<AddBackward0>) time: 2021-12-13 20:01:54
epoch: 245 loss: tensor(0.1642, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:03
epoch: 246 loss: tensor(0.1644, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:11
epoch: 247 loss: tensor(0.1607, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:20
epoch: 248 loss: tensor(0.1644, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:29
epoch: 249 loss: tensor(0.1645, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:38
epoch: 250 loss: tensor(0.1639, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:46
epoch: 251 loss: tensor(0.1598, grad_fn=<AddBackward0>) time: 2021-12-13 20:02:55
epoch: 252 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:04
epoch: 253 loss: tensor(0.1633, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:13
epoch: 254 loss: tensor(0.1627, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:22
epoch: 255 loss: tensor(0.1626, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:30
epoch: 256 loss: tensor(0.1608, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:39
epoch: 257 loss: tensor(0.1619, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:48
epoch: 258 loss: tensor(0.1647, grad_fn=<AddBackward0>) time: 2021-12-13 20:03:57
epoch: 259 loss: tensor(0.1629, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:05
epoch: 260 loss: tensor(0.1666, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:14
epoch: 261 loss: tensor(0.1627, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:23
epoch: 262 loss: tensor(0.1629, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:32
epoch: 263 loss: tensor(0.1600, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:41
epoch: 264 loss: tensor(0.1644, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:49
epoch: 265 loss: tensor(0.1646, grad_fn=<AddBackward0>) time: 2021-12-13 20:04:58
epoch: 266 loss: tensor(0.1626, grad_fn=<AddBackward0>) time: 2021-12-13 20:05:07
epoch: 267 loss: tensor(0.1641, grad_fn=<AddBackward0>) time: 2021-12-13 20:05:16
epoch: 268 loss: tensor(0.1619, grad_fn=<AddBackward0>) time: 2021-12-13 20:05:24
epoch: 269 loss: tensor(0.1598, grad_fn=<AddBackward0>) time: 2021-12-13 20:05:33
save model time: 2021-12-13 20:05:33
load model time: 2021-12-13 20:05:33
train accuracy 1.0 1.0 None
test accuracy 0.8615 0.8615 None
train confusion matrix
 [[5000    0    0    0    0    0    0    0    0    0]
 [   0 5000    0    0    0    0    0    0    0    0]
 [   0    0 5000    0    0    0    0    0    0    0]
 [   0    0    0 5000    0    0    0    0    0    0]
 [   0    0    0    0 5000    0    0    0    0    0]
 [   0    0    0    0    0 5000    0    0    0    0]
 [   0    0    0    0    0    0 5000    0    0    0]
 [   0    0    0    0    0    0    0 5000    0    0]
 [   0    0    0    0    0    0    0    0 5000    0]
 [   0    0    0    0    0    0    0    0    0 5000]]
test confusion matrix
 [[913   3  22   7   9   2   4   4  23  13]
 [  9 917   2   5   1   2   3   1  11  49]
 [ 45   0 782  40  49  31  37   9   6   1]
 [ 22   0  48 720  32 108  43  13   8   6]
 [ 14   1  29  26 870  16  18  25   0   1]
 [ 13   0  19 115  30 784  12  27   0   0]
 [  4   1  20  24  18  16 910   2   5   0]
 [ 12   2  15  28  28  26   3 881   2   3]
 [ 36   4   5   5   2   4   5   1 927  11]
 [ 16  37   1   5   3   3   4   7  13 911]]
end time: 2021-12-13 20:05:39
load data from pickle
load model
test accuracy 0.8615 0.8615 None
test confusion matrix
 [[913   3  22   7   9   2   4   4  23  13]
 [  9 917   2   5   1   2   3   1  11  49]
 [ 45   0 782  40  49  31  37   9   6   1]
 [ 22   0  48 720  32 108  43  13   8   6]
 [ 14   1  29  26 870  16  18  25   0   1]
 [ 13   0  19 115  30 784  12  27   0   0]
 [  4   1  20  24  18  16 910   2   5   0]
 [ 12   2  15  28  28  26   3 881   2   3]
 [ 36   4   5   5   2   4   5   1 927  11]
 [ 16  37   1   5   3   3   4   7  13 911]]
analyze weights (10, 4096)
weights avg square norm 2.8836565
weights norm [1.6915607 1.6983268 1.6902978 1.6813644 1.6989385 1.7140936 1.7042892
 1.7022805 1.698691  1.7012817]
cos weights matrix [[ 1.         -0.10524213 -0.078415   -0.12622875 -0.10801017 -0.16418265
  -0.14864577 -0.11732449 -0.05818803 -0.08888385]
 [-0.10524213  1.         -0.13264365 -0.13254067 -0.14212181 -0.12975597
  -0.09738463 -0.11964639 -0.08286697 -0.05815411]
 [-0.078415   -0.13264365  1.         -0.10748146 -0.08976571 -0.09588628
  -0.09105749 -0.11258855 -0.13234201 -0.15478902]
 [-0.12622875 -0.13254067 -0.10748146  1.         -0.10520584 -0.06179605
  -0.08990195 -0.10999345 -0.13187478 -0.1246083 ]
 [-0.10801017 -0.14212181 -0.08976571 -0.10520584  1.         -0.10668766
  -0.08771352 -0.08167814 -0.13892026 -0.14030784]
 [-0.16418265 -0.12975597 -0.09588628 -0.06179605 -0.10668766  1.
  -0.11582275 -0.07920564 -0.12376219 -0.13290277]
 [-0.14864577 -0.09738463 -0.09105749 -0.08990195 -0.08771352 -0.11582275
   1.         -0.15074688 -0.10562364 -0.11690377]
 [-0.11732449 -0.11964639 -0.11258855 -0.10999345 -0.08167814 -0.07920564
  -0.15074688  1.         -0.13651429 -0.09519002]
 [-0.05818803 -0.08286697 -0.13234201 -0.13187478 -0.13892026 -0.12376219
  -0.10562364 -0.13651429  1.         -0.0903324 ]
 [-0.08888385 -0.05815411 -0.15478902 -0.1246083  -0.14030784 -0.13290277
  -0.11690377 -0.09519002 -0.0903324   1.        ]]
between class weights cosine [-0.10524213 -0.078415   -0.12622875 -0.10801017 -0.16418265 -0.14864577
 -0.11732449 -0.05818803 -0.08888385 -0.10524213 -0.13264365 -0.13254067
 -0.14212181 -0.12975597 -0.09738463 -0.11964639 -0.08286697 -0.05815411
 -0.078415   -0.13264365 -0.10748146 -0.08976571 -0.09588628 -0.09105749
 -0.11258855 -0.13234201 -0.15478902 -0.12622875 -0.13254067 -0.10748146
 -0.10520584 -0.06179605 -0.08990195 -0.10999345 -0.13187478 -0.1246083
 -0.10801017 -0.14212181 -0.08976571 -0.10520584 -0.10668766 -0.08771352
 -0.08167814 -0.13892026 -0.14030784 -0.16418265 -0.12975597 -0.09588628
 -0.06179605 -0.10668766 -0.11582275 -0.07920564 -0.12376219 -0.13290277
 -0.14864577 -0.09738463 -0.09105749 -0.08990195 -0.08771352 -0.11582275
 -0.15074688 -0.10562364 -0.11690377 -0.11732449 -0.11964639 -0.11258855
 -0.10999345 -0.08167814 -0.07920564 -0.15074688 -0.13651429 -0.09519002
 -0.05818803 -0.08286697 -0.13234201 -0.13187478 -0.13892026 -0.12376219
 -0.10562364 -0.13651429 -0.0903324  -0.08888385 -0.05815411 -0.15478902
 -0.1246083  -0.14030784 -0.13290277 -0.11690377 -0.09519002 -0.0903324 ]
std weights norm over avg weights norm 0.0049498845
avg between-class weights cosine -0.11110750469896528
std between-class weights cosine 0.025686262517413464
avg weights cosine to -1/(C-1) 0.0213693454677676
total features (50000, 4096)
total labels (50000,)
feature norm list [22.459222772027303, 21.943704112202862, 22.227909598226255, 21.608721921801198, 23.49610393403261, 23.05800545377591, 23.072939276362437, 22.13420043117317, 21.81915478712848, 22.85316301981888]
avg square feature norm 22.46731253065491
analyze features
features avg square norm 22.389015174677503
features norm [4.73108944 4.67977539 4.70643915 4.63907388 4.84234683 4.78503349
 4.79261925 4.69805567 4.66453217 4.77403558]
cos features matrix [[ 1.         -0.11830655 -0.0678882  -0.1197816  -0.11568943 -0.13704027
  -0.14404354 -0.11252947 -0.07409163 -0.10927547]
 [-0.11830655  1.         -0.12729689 -0.11500716 -0.14248949 -0.13416943
  -0.10960352 -0.1273403  -0.06045013 -0.05234872]
 [-0.0678882  -0.12729689  1.         -0.09129906 -0.09602066 -0.11508156
  -0.08445439 -0.1288593  -0.13247481 -0.15129269]
 [-0.1197816  -0.11500716 -0.09129906  1.         -0.12154169 -0.05770887
  -0.09237184 -0.12466084 -0.13037347 -0.1263693 ]
 [-0.11568943 -0.14248949 -0.09602066 -0.12154169  1.         -0.11723206
  -0.07371256 -0.06105987 -0.14674432 -0.15224916]
 [-0.13704027 -0.13416943 -0.11508156 -0.05770887 -0.11723206  1.
  -0.11990698 -0.07624995 -0.11974633 -0.13412697]
 [-0.14404354 -0.10960352 -0.08445439 -0.09237184 -0.07371256 -0.11990698
   1.         -0.15014207 -0.11271989 -0.12784891]
 [-0.11252947 -0.1273403  -0.1288593  -0.12466084 -0.06105987 -0.07624995
  -0.15014207  1.         -0.13326145 -0.08027961]
 [-0.07409163 -0.06045013 -0.13247481 -0.13037347 -0.14674432 -0.11974633
  -0.11271989 -0.13326145  1.         -0.07392862]
 [-0.10927547 -0.05234872 -0.15129269 -0.1263693  -0.15224916 -0.13412697
  -0.12784891 -0.08027961 -0.07392862  1.        ]]
between class features cosine [-0.11830655 -0.0678882  -0.1197816  -0.11568943 -0.13704027 -0.14404354
 -0.11252947 -0.07409163 -0.10927547 -0.11830655 -0.12729689 -0.11500716
 -0.14248949 -0.13416943 -0.10960352 -0.1273403  -0.06045013 -0.05234872
 -0.0678882  -0.12729689 -0.09129906 -0.09602066 -0.11508156 -0.08445439
 -0.1288593  -0.13247481 -0.15129269 -0.1197816  -0.11500716 -0.09129906
 -0.12154169 -0.05770887 -0.09237184 -0.12466084 -0.13037347 -0.1263693
 -0.11568943 -0.14248949 -0.09602066 -0.12154169 -0.11723206 -0.07371256
 -0.06105987 -0.14674432 -0.15224916 -0.13704027 -0.13416943 -0.11508156
 -0.05770887 -0.11723206 -0.11990698 -0.07624995 -0.11974633 -0.13412697
 -0.14404354 -0.10960352 -0.08445439 -0.09237184 -0.07371256 -0.11990698
 -0.15014207 -0.11271989 -0.12784891 -0.11252947 -0.1273403  -0.1288593
 -0.12466084 -0.06105987 -0.07624995 -0.15014207 -0.13326145 -0.08027961
 -0.07409163 -0.06045013 -0.13247481 -0.13037347 -0.14674432 -0.11974633
 -0.11271989 -0.13326145 -0.07392862 -0.10927547 -0.05234872 -0.15129269
 -0.1263693  -0.15224916 -0.13412697 -0.12784891 -0.08027961 -0.07392862]
std features norm over avg features norm 0.013054139033919953
avg between-class features cosine -0.11109042283306661
std between-class features cosine 0.027684493109713704
avg features cosine to -1/(C-1) 0.0229586305708552
analyze the duality of weights and features
dual distance 0.10698201968126451
dual distance square 0.011445152535082468
(base) ]0;root@DESKTOP-VFHBUQ9: /mnt/e/GitHub Repo/LPMroot@DESKTOP-VFHBUQ9:/mnt/e/GitHub Repo/LPM# exit
exit

Script done on 2021-12-13 20:06:53+0800
