Script started on 2021-12-13 20:12:11+0800
(base) ]0;root@DESKTOP-VFHBUQ9: /mnt/e/GitHub Repo/LPMroot@DESKTOP-VFHBUQ9:/mnt/e/GitHub Repo/LPM# sh run-mnist-collapse.sh 
weight ratio 10
save test data time: 2021-12-13 20:12:22
test label num [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
save train data time: 2021-12-13 20:12:29
train label num [6000, 6000, 6000, 6000, 6000, 6, 6, 6, 6, 6]
load data from pickle time: 2021-12-13 20:12:51
weighted idx [5, 8, 9, 11, 13, 15, 18, 19, 20, 21, 24, 25, 26, 27, 28, 32, 34, 39, 44, 46, 51, 53, 54, 59, 64, 65, 70, 95, 102, 106]
build model time: 2021-12-13 20:12:59
train model time: 2021-12-13 20:12:59
weighted idx [5, 8, 9, 11, 13, 15, 18, 19, 20, 21, 24, 25, 26, 27, 28, 32, 34, 39, 44, 46, 51, 53, 54, 59, 64, 65, 70, 95, 102, 106]
epoch: 0 loss: tensor(140.7272, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:04
epoch: 1 loss: tensor(49.8837, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:10
epoch: 2 loss: tensor(38.6258, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:15
epoch: 3 loss: tensor(33.4682, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:20
epoch: 4 loss: tensor(27.9500, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:25
epoch: 5 loss: tensor(23.4339, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:31
epoch: 6 loss: tensor(23.8114, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:36
epoch: 7 loss: tensor(20.6642, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:41
epoch: 8 loss: tensor(18.4393, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:46
epoch: 9 loss: tensor(16.4107, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:52
epoch: 10 loss: tensor(15.2033, grad_fn=<AddBackward0>) time: 2021-12-13 20:13:57
epoch: 11 loss: tensor(13.7259, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:02
epoch: 12 loss: tensor(13.3844, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:08
epoch: 13 loss: tensor(12.4941, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:13
epoch: 14 loss: tensor(11.8436, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:18
epoch: 15 loss: tensor(11.2248, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:24
epoch: 16 loss: tensor(10.9536, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:29
epoch: 17 loss: tensor(10.2384, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:34
epoch: 18 loss: tensor(9.5854, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:40
epoch: 19 loss: tensor(9.2000, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:45
epoch: 20 loss: tensor(8.2011, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:50
epoch: 21 loss: tensor(8.8744, grad_fn=<AddBackward0>) time: 2021-12-13 20:14:56
epoch: 22 loss: tensor(8.9782, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:01
epoch: 23 loss: tensor(7.3514, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:06
epoch: 24 loss: tensor(6.9573, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:12
epoch: 25 loss: tensor(7.0905, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:17
epoch: 26 loss: tensor(6.4696, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:22
epoch: 27 loss: tensor(6.0810, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:28
epoch: 28 loss: tensor(5.7536, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:33
epoch: 29 loss: tensor(5.4858, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:38
epoch: 30 loss: tensor(5.3231, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:44
epoch: 31 loss: tensor(5.3554, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:49
epoch: 32 loss: tensor(4.6186, grad_fn=<AddBackward0>) time: 2021-12-13 20:15:55
epoch: 33 loss: tensor(5.1307, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:00
epoch: 34 loss: tensor(4.8055, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:05
epoch: 35 loss: tensor(4.3782, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:11
epoch: 36 loss: tensor(3.8700, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:16
epoch: 37 loss: tensor(3.1841, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:21
epoch: 38 loss: tensor(3.2987, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:27
epoch: 39 loss: tensor(3.2391, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:32
epoch: 40 loss: tensor(3.1692, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:37
epoch: 41 loss: tensor(3.0478, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:43
epoch: 42 loss: tensor(2.6209, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:48
epoch: 43 loss: tensor(3.1109, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:54
epoch: 44 loss: tensor(2.7273, grad_fn=<AddBackward0>) time: 2021-12-13 20:16:59
epoch: 45 loss: tensor(3.0716, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:04
epoch: 46 loss: tensor(2.4157, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:10
epoch: 47 loss: tensor(2.6435, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:15
epoch: 48 loss: tensor(2.0798, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:20
epoch: 49 loss: tensor(1.7454, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:26
epoch: 50 loss: tensor(2.2143, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:31
epoch: 51 loss: tensor(2.5873, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:36
epoch: 52 loss: tensor(2.9903, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:42
epoch: 53 loss: tensor(1.7101, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:47
epoch: 54 loss: tensor(1.5021, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:53
epoch: 55 loss: tensor(2.0728, grad_fn=<AddBackward0>) time: 2021-12-13 20:17:58
epoch: 56 loss: tensor(1.9367, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:03
epoch: 57 loss: tensor(1.2924, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:09
epoch: 58 loss: tensor(1.7666, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:14
epoch: 59 loss: tensor(2.2436, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:19
epoch: 60 loss: tensor(1.5634, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:25
epoch: 61 loss: tensor(2.1094, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:30
epoch: 62 loss: tensor(3.2956, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:35
epoch: 63 loss: tensor(1.7608, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:41
epoch: 64 loss: tensor(3.1710, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:46
epoch: 65 loss: tensor(1.5841, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:52
epoch: 66 loss: tensor(1.7092, grad_fn=<AddBackward0>) time: 2021-12-13 20:18:57
epoch: 67 loss: tensor(1.8591, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:02
epoch: 68 loss: tensor(1.4794, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:08
epoch: 69 loss: tensor(2.5645, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:13
epoch: 70 loss: tensor(1.1017, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:18
epoch: 71 loss: tensor(1.7125, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:24
epoch: 72 loss: tensor(1.5615, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:29
epoch: 73 loss: tensor(1.5334, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:35
epoch: 74 loss: tensor(1.4056, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:40
epoch: 75 loss: tensor(1.9491, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:45
epoch: 76 loss: tensor(1.9766, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:51
epoch: 77 loss: tensor(1.0710, grad_fn=<AddBackward0>) time: 2021-12-13 20:19:56
epoch: 78 loss: tensor(1.4156, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:01
epoch: 79 loss: tensor(1.5173, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:07
epoch: 80 loss: tensor(0.8899, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:12
epoch: 81 loss: tensor(2.4406, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:17
epoch: 82 loss: tensor(1.4103, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:23
epoch: 83 loss: tensor(1.5630, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:28
epoch: 84 loss: tensor(2.2276, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:33
epoch: 85 loss: tensor(0.7255, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:39
epoch: 86 loss: tensor(0.8795, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:44
epoch: 87 loss: tensor(0.8420, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:50
epoch: 88 loss: tensor(1.6260, grad_fn=<AddBackward0>) time: 2021-12-13 20:20:55
epoch: 89 loss: tensor(1.6262, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:00
epoch: 90 loss: tensor(1.6751, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:06
epoch: 91 loss: tensor(1.3131, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:11
epoch: 92 loss: tensor(1.3277, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:16
epoch: 93 loss: tensor(0.5338, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:22
epoch: 94 loss: tensor(0.4964, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:27
epoch: 95 loss: tensor(1.7921, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:32
epoch: 96 loss: tensor(1.8185, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:38
epoch: 97 loss: tensor(1.2371, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:43
epoch: 98 loss: tensor(1.6194, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:49
epoch: 99 loss: tensor(1.3970, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:54
epoch: 100 loss: tensor(1.7604, grad_fn=<AddBackward0>) time: 2021-12-13 20:21:59
epoch: 101 loss: tensor(1.8996, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:05
epoch: 102 loss: tensor(1.6319, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:10
epoch: 103 loss: tensor(0.9317, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:16
epoch: 104 loss: tensor(1.0152, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:21
epoch: 105 loss: tensor(0.4720, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:26
epoch: 106 loss: tensor(0.7574, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:32
epoch: 107 loss: tensor(2.0880, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:37
epoch: 108 loss: tensor(1.4478, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:43
epoch: 109 loss: tensor(0.8929, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:48
epoch: 110 loss: tensor(0.9683, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:53
epoch: 111 loss: tensor(1.0826, grad_fn=<AddBackward0>) time: 2021-12-13 20:22:59
epoch: 112 loss: tensor(1.6941, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:04
epoch: 113 loss: tensor(1.6261, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:10
epoch: 114 loss: tensor(1.8295, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:15
epoch: 115 loss: tensor(1.7722, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:20
divide current learning rate by 10
epoch: 116 loss: tensor(0.4364, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:26
epoch: 117 loss: tensor(0.1594, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:31
epoch: 118 loss: tensor(0.1231, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:37
epoch: 119 loss: tensor(0.1729, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:42
epoch: 120 loss: tensor(0.1345, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:48
epoch: 121 loss: tensor(0.1015, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:53
epoch: 122 loss: tensor(0.0906, grad_fn=<AddBackward0>) time: 2021-12-13 20:23:58
epoch: 123 loss: tensor(0.0858, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:04
epoch: 124 loss: tensor(0.0820, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:09
epoch: 125 loss: tensor(0.0785, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:14
epoch: 126 loss: tensor(0.0763, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:20
epoch: 127 loss: tensor(0.0770, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:25
epoch: 128 loss: tensor(0.0763, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:31
epoch: 129 loss: tensor(0.0817, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:36
epoch: 130 loss: tensor(0.0772, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:42
epoch: 131 loss: tensor(0.0736, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:47
epoch: 132 loss: tensor(0.0743, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:53
epoch: 133 loss: tensor(0.0724, grad_fn=<AddBackward0>) time: 2021-12-13 20:24:58
epoch: 134 loss: tensor(0.0807, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:03
epoch: 135 loss: tensor(0.0748, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:09
epoch: 136 loss: tensor(0.0749, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:14
epoch: 137 loss: tensor(0.0718, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:19
epoch: 138 loss: tensor(0.0696, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:25
epoch: 139 loss: tensor(0.0707, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:30
epoch: 140 loss: tensor(0.0689, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:36
epoch: 141 loss: tensor(0.0704, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:41
epoch: 142 loss: tensor(0.0721, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:47
epoch: 143 loss: tensor(0.0774, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:52
epoch: 144 loss: tensor(0.0709, grad_fn=<AddBackward0>) time: 2021-12-13 20:25:58
epoch: 145 loss: tensor(0.0695, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:03
epoch: 146 loss: tensor(0.0714, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:08
epoch: 147 loss: tensor(0.0697, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:14
epoch: 148 loss: tensor(0.0747, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:19
epoch: 149 loss: tensor(0.0733, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:24
epoch: 150 loss: tensor(0.0712, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:30
epoch: 151 loss: tensor(0.0701, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:35
epoch: 152 loss: tensor(0.0728, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:41
epoch: 153 loss: tensor(0.0707, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:46
epoch: 154 loss: tensor(0.0740, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:51
epoch: 155 loss: tensor(0.0687, grad_fn=<AddBackward0>) time: 2021-12-13 20:26:57
epoch: 156 loss: tensor(0.0731, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:02
epoch: 157 loss: tensor(0.0702, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:08
epoch: 158 loss: tensor(0.0713, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:13
epoch: 159 loss: tensor(0.0712, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:18
epoch: 160 loss: tensor(0.0727, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:24
epoch: 161 loss: tensor(0.0725, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:29
epoch: 162 loss: tensor(0.0724, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:34
epoch: 163 loss: tensor(0.0722, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:40
epoch: 164 loss: tensor(0.0729, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:45
epoch: 165 loss: tensor(0.0735, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:51
epoch: 166 loss: tensor(0.0730, grad_fn=<AddBackward0>) time: 2021-12-13 20:27:56
epoch: 167 loss: tensor(0.0717, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:01
epoch: 168 loss: tensor(0.0735, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:07
epoch: 169 loss: tensor(0.0756, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:12
epoch: 170 loss: tensor(0.0736, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:17
epoch: 171 loss: tensor(0.0747, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:23
epoch: 172 loss: tensor(0.0767, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:28
epoch: 173 loss: tensor(0.0740, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:34
epoch: 174 loss: tensor(0.0780, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:39
epoch: 175 loss: tensor(0.0743, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:44
epoch: 176 loss: tensor(0.0759, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:50
epoch: 177 loss: tensor(0.0755, grad_fn=<AddBackward0>) time: 2021-12-13 20:28:55
epoch: 178 loss: tensor(0.0783, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:00
epoch: 179 loss: tensor(0.0780, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:06
epoch: 180 loss: tensor(0.0765, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:11
epoch: 181 loss: tensor(0.0757, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:16
epoch: 182 loss: tensor(0.0749, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:22
epoch: 183 loss: tensor(0.0764, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:27
epoch: 184 loss: tensor(0.0836, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:32
epoch: 185 loss: tensor(0.0755, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:38
epoch: 186 loss: tensor(0.0784, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:43
epoch: 187 loss: tensor(0.0792, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:49
epoch: 188 loss: tensor(0.0762, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:54
epoch: 189 loss: tensor(0.0774, grad_fn=<AddBackward0>) time: 2021-12-13 20:29:59
epoch: 190 loss: tensor(0.0753, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:05
epoch: 191 loss: tensor(0.0747, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:10
epoch: 192 loss: tensor(0.0775, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:15
epoch: 193 loss: tensor(0.0755, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:21
epoch: 194 loss: tensor(0.0789, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:26
epoch: 195 loss: tensor(0.0807, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:31
epoch: 196 loss: tensor(0.0786, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:37
epoch: 197 loss: tensor(0.0785, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:42
epoch: 198 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:48
epoch: 199 loss: tensor(0.0763, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:53
epoch: 200 loss: tensor(0.0767, grad_fn=<AddBackward0>) time: 2021-12-13 20:30:58
epoch: 201 loss: tensor(0.0784, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:04
epoch: 202 loss: tensor(0.0875, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:09
epoch: 203 loss: tensor(0.0810, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:14
epoch: 204 loss: tensor(0.0781, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:20
epoch: 205 loss: tensor(0.0780, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:25
epoch: 206 loss: tensor(0.0766, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:30
epoch: 207 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:36
epoch: 208 loss: tensor(0.0802, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:41
epoch: 209 loss: tensor(0.0810, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:46
epoch: 210 loss: tensor(0.0779, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:52
epoch: 211 loss: tensor(0.0798, grad_fn=<AddBackward0>) time: 2021-12-13 20:31:57
epoch: 212 loss: tensor(0.0782, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:03
epoch: 213 loss: tensor(0.0808, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:08
epoch: 214 loss: tensor(0.0802, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:13
epoch: 215 loss: tensor(0.0883, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:19
epoch: 216 loss: tensor(0.0882, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:24
epoch: 217 loss: tensor(0.0809, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:29
epoch: 218 loss: tensor(0.0852, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:35
epoch: 219 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:40
epoch: 220 loss: tensor(0.0776, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:46
epoch: 221 loss: tensor(0.0799, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:51
epoch: 222 loss: tensor(0.0792, grad_fn=<AddBackward0>) time: 2021-12-13 20:32:56
epoch: 223 loss: tensor(0.0791, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:02
epoch: 224 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:07
epoch: 225 loss: tensor(0.0821, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:12
epoch: 226 loss: tensor(0.0804, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:18
epoch: 227 loss: tensor(0.0873, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:23
epoch: 228 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:28
epoch: 229 loss: tensor(0.0798, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:34
epoch: 230 loss: tensor(0.0809, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:39
epoch: 231 loss: tensor(0.0819, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:44
epoch: 232 loss: tensor(0.0819, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:50
divide current learning rate by 10
epoch: 233 loss: tensor(0.0820, grad_fn=<AddBackward0>) time: 2021-12-13 20:33:55
epoch: 234 loss: tensor(0.0802, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:01
epoch: 235 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:06
epoch: 236 loss: tensor(0.0816, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:11
epoch: 237 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:17
epoch: 238 loss: tensor(0.0799, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:22
epoch: 239 loss: tensor(0.0808, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:27
epoch: 240 loss: tensor(0.0850, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:33
epoch: 241 loss: tensor(0.0887, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:38
epoch: 242 loss: tensor(0.0808, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:43
epoch: 243 loss: tensor(0.0802, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:49
epoch: 244 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:34:54
epoch: 245 loss: tensor(0.0813, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:00
epoch: 246 loss: tensor(0.0820, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:05
epoch: 247 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:10
epoch: 248 loss: tensor(0.0829, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:16
epoch: 249 loss: tensor(0.0804, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:21
epoch: 250 loss: tensor(0.0813, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:26
epoch: 251 loss: tensor(0.0785, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:32
epoch: 252 loss: tensor(0.0951, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:37
epoch: 253 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:43
epoch: 254 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:48
epoch: 255 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:53
epoch: 256 loss: tensor(0.0810, grad_fn=<AddBackward0>) time: 2021-12-13 20:35:59
epoch: 257 loss: tensor(0.0793, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:04
epoch: 258 loss: tensor(0.0820, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:09
epoch: 259 loss: tensor(0.0775, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:15
epoch: 260 loss: tensor(0.0835, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:20
epoch: 261 loss: tensor(0.0816, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:26
epoch: 262 loss: tensor(0.0794, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:31
epoch: 263 loss: tensor(0.0825, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:36
epoch: 264 loss: tensor(0.0793, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:42
epoch: 265 loss: tensor(0.0846, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:47
epoch: 266 loss: tensor(0.0792, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:52
epoch: 267 loss: tensor(0.0804, grad_fn=<AddBackward0>) time: 2021-12-13 20:36:58
epoch: 268 loss: tensor(0.0807, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:03
epoch: 269 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:08
epoch: 270 loss: tensor(0.0816, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:14
epoch: 271 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:19
epoch: 272 loss: tensor(0.0775, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:24
epoch: 273 loss: tensor(0.0801, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:30
epoch: 274 loss: tensor(0.0811, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:35
epoch: 275 loss: tensor(0.0787, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:41
epoch: 276 loss: tensor(0.0834, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:46
epoch: 277 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:51
epoch: 278 loss: tensor(0.0876, grad_fn=<AddBackward0>) time: 2021-12-13 20:37:57
epoch: 279 loss: tensor(0.0781, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:02
epoch: 280 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:08
epoch: 281 loss: tensor(0.0790, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:13
epoch: 282 loss: tensor(0.0783, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:18
epoch: 283 loss: tensor(0.0784, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:23
epoch: 284 loss: tensor(0.0787, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:29
epoch: 285 loss: tensor(0.0909, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:34
epoch: 286 loss: tensor(0.0814, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:39
epoch: 287 loss: tensor(0.0822, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:45
epoch: 288 loss: tensor(0.0781, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:50
epoch: 289 loss: tensor(0.0812, grad_fn=<AddBackward0>) time: 2021-12-13 20:38:56
epoch: 290 loss: tensor(0.0818, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:01
epoch: 291 loss: tensor(0.0824, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:06
epoch: 292 loss: tensor(0.0822, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:12
epoch: 293 loss: tensor(0.0819, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:17
epoch: 294 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:22
epoch: 295 loss: tensor(0.0794, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:28
epoch: 296 loss: tensor(0.0773, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:33
epoch: 297 loss: tensor(0.0791, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:38
epoch: 298 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:44
epoch: 299 loss: tensor(0.0814, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:49
epoch: 300 loss: tensor(0.0800, grad_fn=<AddBackward0>) time: 2021-12-13 20:39:54
epoch: 301 loss: tensor(0.0817, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:00
epoch: 302 loss: tensor(0.0779, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:05
epoch: 303 loss: tensor(0.0809, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:10
epoch: 304 loss: tensor(0.0822, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:16
epoch: 305 loss: tensor(0.0793, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:21
epoch: 306 loss: tensor(0.0827, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:26
epoch: 307 loss: tensor(0.0820, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:32
epoch: 308 loss: tensor(0.0811, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:37
epoch: 309 loss: tensor(0.0778, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:42
epoch: 310 loss: tensor(0.0801, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:48
epoch: 311 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:53
epoch: 312 loss: tensor(0.0801, grad_fn=<AddBackward0>) time: 2021-12-13 20:40:58
epoch: 313 loss: tensor(0.0808, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:04
epoch: 314 loss: tensor(0.0890, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:09
epoch: 315 loss: tensor(0.0785, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:14
epoch: 316 loss: tensor(0.0818, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:20
epoch: 317 loss: tensor(0.0788, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:25
epoch: 318 loss: tensor(0.0812, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:30
epoch: 319 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:36
epoch: 320 loss: tensor(0.0802, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:41
epoch: 321 loss: tensor(0.0835, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:46
epoch: 322 loss: tensor(0.0788, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:52
epoch: 323 loss: tensor(0.0815, grad_fn=<AddBackward0>) time: 2021-12-13 20:41:57
epoch: 324 loss: tensor(0.0825, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:02
epoch: 325 loss: tensor(0.0795, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:08
epoch: 326 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:13
epoch: 327 loss: tensor(0.0804, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:18
epoch: 328 loss: tensor(0.0817, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:24
epoch: 329 loss: tensor(0.0816, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:29
epoch: 330 loss: tensor(0.0794, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:34
epoch: 331 loss: tensor(0.0783, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:40
epoch: 332 loss: tensor(0.0803, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:45
epoch: 333 loss: tensor(0.0832, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:50
epoch: 334 loss: tensor(0.0887, grad_fn=<AddBackward0>) time: 2021-12-13 20:42:56
epoch: 335 loss: tensor(0.0838, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:01
epoch: 336 loss: tensor(0.0807, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:06
epoch: 337 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:12
epoch: 338 loss: tensor(0.0818, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:17
epoch: 339 loss: tensor(0.0810, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:22
epoch: 340 loss: tensor(0.0783, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:28
epoch: 341 loss: tensor(0.0825, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:33
epoch: 342 loss: tensor(0.0807, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:38
epoch: 343 loss: tensor(0.0797, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:44
epoch: 344 loss: tensor(0.0786, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:49
epoch: 345 loss: tensor(0.0816, grad_fn=<AddBackward0>) time: 2021-12-13 20:43:54
epoch: 346 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:44:00
epoch: 347 loss: tensor(0.0835, grad_fn=<AddBackward0>) time: 2021-12-13 20:44:05
epoch: 348 loss: tensor(0.0778, grad_fn=<AddBackward0>) time: 2021-12-13 20:44:10
epoch: 349 loss: tensor(0.0796, grad_fn=<AddBackward0>) time: 2021-12-13 20:44:16
save model time: 2021-12-13 20:44:16
load model time: 2021-12-13 20:44:16
train accuracy 1.0 1.0 1.0
test accuracy 0.7394 0.956 0.5228
train confusion matrix
 [[6000    0    0    0    0    0    0    0    0    0]
 [   0 6000    0    0    0    0    0    0    0    0]
 [   0    0 6000    0    0    0    0    0    0    0]
 [   0    0    0 6000    0    0    0    0    0    0]
 [   0    0    0    0 6000    0    0    0    0    0]
 [   0    0    0    0    0    6    0    0    0    0]
 [   0    0    0    0    0    0    6    0    0    0]
 [   0    0    0    0    0    0    0    6    0    0]
 [   0    0    0    0    0    0    0    0    6    0]
 [   0    0    0    0    0    0    0    0    0    6]]
test confusion matrix
 [[957   2  19  17   5   0   0   0   0   0]
 [  3 990   1   5   1   0   0   0   0   0]
 [ 19   1 938   7  35   0   0   0   0   0]
 [ 20   1   6 950  23   0   0   0   0   0]
 [  2   0  35  18 945   0   0   0   0   0]
 [123   0   3   4   5 733   0 125   1   6]
 [358   1 170  39 432   0   0   0   0   0]
 [  3   0   1   0   0  78   0 871   0  47]
 [329   3  85  30 168  20   2   3 354   6]
 [  8   0   0   9  37  71   0 219   0 656]]
end time: 2021-12-13 20:44:20
weight ratio 10
load data from pickle
load model
test accuracy 0.7394 0.956 0.5228
test confusion matrix
 [[957   2  19  17   5   0   0   0   0   0]
 [  3 990   1   5   1   0   0   0   0   0]
 [ 19   1 938   7  35   0   0   0   0   0]
 [ 20   1   6 950  23   0   0   0   0   0]
 [  2   0  35  18 945   0   0   0   0   0]
 [123   0   3   4   5 733   0 125   1   6]
 [358   1 170  39 432   0   0   0   0   0]
 [  3   0   1   0   0  78   0 871   0  47]
 [329   3  85  30 168  20   2   3 354   6]
 [  8   0   0   9  37  71   0 219   0 656]]
analyze weights (10, 4096)
weights avg square norm 2.2153625
weights norm [1.94141    1.9030482  1.9590415  1.9282001  1.9354972  0.8388477
 0.81419253 0.84092814 0.8355203  0.83017033]
cos weights matrix [[ 1.         -0.1846416  -0.1295781  -0.15095238 -0.20644155 -0.05657358
  -0.10056886 -0.17715758 -0.10729916 -0.33401123]
 [-0.1846416   1.         -0.20621051 -0.15754503 -0.18291412 -0.10563045
  -0.13821277 -0.12428397 -0.12482932 -0.08870737]
 [-0.1295781  -0.20621051  1.         -0.18258318 -0.13502327 -0.19065814
  -0.16567083 -0.17032868 -0.10157809 -0.21394394]
 [-0.15095238 -0.15754503 -0.18258318  1.         -0.13423957 -0.18660714
  -0.19227198 -0.11461063 -0.18075769 -0.19001451]
 [-0.20644155 -0.18291412 -0.13502327 -0.13423957  1.         -0.22206317
  -0.16504255 -0.13312799 -0.1770018  -0.10010612]
 [-0.05657358 -0.10563045 -0.19065814 -0.18660714 -0.22206317  1.
  -0.08332867  0.29793176  0.29425758  0.24961856]
 [-0.10056886 -0.13821277 -0.16567083 -0.19227198 -0.16504255 -0.08332867
   1.          0.3134169   0.26480082  0.2946409 ]
 [-0.17715758 -0.12428397 -0.17032868 -0.11461063 -0.13312799  0.29793176
   0.3134169   1.         -0.25410101  0.31228089]
 [-0.10729916 -0.12482932 -0.10157809 -0.18075769 -0.1770018   0.29425758
   0.26480082 -0.25410101  1.          0.30416796]
 [-0.33401123 -0.08870737 -0.21394394 -0.19001451 -0.10010612  0.24961856
   0.2946409   0.31228089  0.30416796  1.        ]]
between class weights cosine [-0.1846416  -0.1295781  -0.15095238 -0.20644155 -0.05657358 -0.10056886
 -0.17715758 -0.10729916 -0.33401123 -0.1846416  -0.20621051 -0.15754503
 -0.18291412 -0.10563045 -0.13821277 -0.12428397 -0.12482932 -0.08870737
 -0.1295781  -0.20621051 -0.18258318 -0.13502327 -0.19065814 -0.16567083
 -0.17032868 -0.10157809 -0.21394394 -0.15095238 -0.15754503 -0.18258318
 -0.13423957 -0.18660714 -0.19227198 -0.11461063 -0.18075769 -0.19001451
 -0.20644155 -0.18291412 -0.13502327 -0.13423957 -0.22206317 -0.16504255
 -0.13312799 -0.1770018  -0.10010612 -0.05657358 -0.10563045 -0.19065814
 -0.18660714 -0.22206317 -0.08332867  0.29793176  0.29425758  0.24961856
 -0.10056886 -0.13821277 -0.16567083 -0.19227198 -0.16504255 -0.08332867
  0.3134169   0.26480082  0.2946409  -0.17715758 -0.12428397 -0.17032868
 -0.11461063 -0.13312799  0.29793176  0.3134169  -0.25410101  0.31228089
 -0.10729916 -0.12482932 -0.10157809 -0.18075769 -0.1770018   0.29425758
  0.26480082 -0.25410101  0.30416796 -0.33401123 -0.08870737 -0.21394394
 -0.19001451 -0.10010612  0.24961856  0.2946409   0.31228089  0.30416796]
std weights norm over avg weights norm 0.39846182
avg between-class weights cosine -0.07861113722125689
std between-class weights cosine 0.17876896403137058
avg weights cosine to -1/(C-1) 0.11706006327345048
weights cosine for small classes [[ 1.         -0.08332867  0.29793176  0.29425758  0.24961856]
 [-0.08332867  1.          0.3134169   0.26480082  0.2946409 ]
 [ 0.29793176  0.3134169   1.         -0.25410101  0.31228089]
 [ 0.29425758  0.26480082 -0.25410101  1.          0.30416796]
 [ 0.24961856  0.2946409   0.31228089  0.30416796  1.        ]]
between-calss weights cosine for small classes [-0.08332867175340652, 0.2979317605495453, 0.29425758123397827, 0.2496185600757599, -0.08332867175340652, 0.31341689825057983, 0.2648008167743683, 0.2946408987045288, 0.2979317605495453, 0.31341689825057983, -0.2541010081768036, 0.31228089332580566, 0.29425758123397827, 0.2648008167743683, -0.2541010081768036, 0.3041679561138153, 0.2496185600757599, 0.2946408987045288, 0.31228089332580566, 0.3041679561138153]
avg between-class weights cosine for small classes 0.19936856850981713
std between-class weights cosine for small classes 0.18891622432016142
std weights norm over avg weights norm for small classes 0.011522185
total features (30030, 4096)
total labels (30030,)
feature norm list [14.326394443604071, 15.526873028064175, 14.39007813216806, 15.124750844043946, 14.829434338252096, 231.49236721795083, 212.5162061027673, 228.18898467433416, 214.48812042318613, 270.26857658902617]
avg square feature norm 123.1151785793397
analyze features
features avg square norm 123.07665461572219
features norm [ 3.78111121  3.93794295  3.78766043  3.88322142  3.84316512 15.21339226
 14.5771852  15.10386397 14.64386351 16.43945175]
cos features matrix [[ 1.00000000e+00 -2.66782112e-01 -2.13885208e-01 -2.18255162e-01
  -2.79647712e-01  9.79299857e-02  3.42549834e-02 -1.32142854e-02
   3.25323167e-02 -2.52125324e-02]
 [-2.66782112e-01  1.00000000e+00 -2.68199991e-01 -2.48309158e-01
  -2.46821190e-01 -3.38104468e-03 -1.52112213e-02 -1.71516300e-02
  -1.15772468e-02  9.49986016e-03]
 [-2.13885208e-01 -2.68199991e-01  1.00000000e+00 -2.84819426e-01
  -2.12130064e-01 -4.76348650e-02 -6.58551871e-03 -4.13420869e-02
   2.22825874e-02 -2.39570753e-02]
 [-2.18255162e-01 -2.48309158e-01 -2.84819426e-01  1.00000000e+00
  -2.60296949e-01 -2.05648164e-02 -1.81641603e-02  2.86284089e-02
  -3.52390416e-02 -1.96101256e-02]
 [-2.79647712e-01 -2.46821190e-01 -2.12130064e-01 -2.60296949e-01
   1.00000000e+00 -3.53755460e-02 -1.76370561e-03  3.24038493e-02
  -1.56988817e-02  4.58309705e-02]
 [ 9.79299857e-02 -3.38104468e-03 -4.76348650e-02 -2.05648164e-02
  -3.53755460e-02  1.00000000e+00  6.94912525e-03  5.24540136e-01
   4.39067736e-01  5.83946827e-01]
 [ 3.42549834e-02 -1.52112213e-02 -6.58551871e-03 -1.81641603e-02
  -1.76370561e-03  6.94912525e-03  1.00000000e+00  3.92964072e-01
   3.31736416e-01  4.35556675e-01]
 [-1.32142854e-02 -1.71516300e-02 -4.13420869e-02  2.86284089e-02
   3.24038493e-02  5.24540136e-01  3.92964072e-01  1.00000000e+00
  -3.27343348e-04  5.83072993e-01]
 [ 3.25323167e-02 -1.15772468e-02  2.22825874e-02 -3.52390416e-02
  -1.56988817e-02  4.39067736e-01  3.31736416e-01 -3.27343348e-04
   1.00000000e+00  5.59832488e-01]
 [-2.52125324e-02  9.49986016e-03 -2.39570753e-02 -1.96101256e-02
   4.58309705e-02  5.83946827e-01  4.35556675e-01  5.83072993e-01
   5.59832488e-01  1.00000000e+00]]
between class features cosine [-2.66782112e-01 -2.13885208e-01 -2.18255162e-01 -2.79647712e-01
  9.79299857e-02  3.42549834e-02 -1.32142854e-02  3.25323167e-02
 -2.52125324e-02 -2.66782112e-01 -2.68199991e-01 -2.48309158e-01
 -2.46821190e-01 -3.38104468e-03 -1.52112213e-02 -1.71516300e-02
 -1.15772468e-02  9.49986016e-03 -2.13885208e-01 -2.68199991e-01
 -2.84819426e-01 -2.12130064e-01 -4.76348650e-02 -6.58551871e-03
 -4.13420869e-02  2.22825874e-02 -2.39570753e-02 -2.18255162e-01
 -2.48309158e-01 -2.84819426e-01 -2.60296949e-01 -2.05648164e-02
 -1.81641603e-02  2.86284089e-02 -3.52390416e-02 -1.96101256e-02
 -2.79647712e-01 -2.46821190e-01 -2.12130064e-01 -2.60296949e-01
 -3.53755460e-02 -1.76370561e-03  3.24038493e-02 -1.56988817e-02
  4.58309705e-02  9.79299857e-02 -3.38104468e-03 -4.76348650e-02
 -2.05648164e-02 -3.53755460e-02  6.94912525e-03  5.24540136e-01
  4.39067736e-01  5.83946827e-01  3.42549834e-02 -1.52112213e-02
 -6.58551871e-03 -1.81641603e-02 -1.76370561e-03  6.94912525e-03
  3.92964072e-01  3.31736416e-01  4.35556675e-01 -1.32142854e-02
 -1.71516300e-02 -4.13420869e-02  2.86284089e-02  3.24038493e-02
  5.24540136e-01  3.92964072e-01 -3.27343348e-04  5.83072993e-01
  3.25323167e-02 -1.15772468e-02  2.22825874e-02 -3.52390416e-02
 -1.56988817e-02  4.39067736e-01  3.31736416e-01 -3.27343348e-04
  5.59832488e-01 -2.52125324e-02  9.49986016e-03 -2.39570753e-02
 -1.96101256e-02  4.58309705e-02  5.83946827e-01  4.35556675e-01
  5.83072993e-01  5.59832488e-01]
std features norm over avg features norm 0.5980774109312709
avg between-class features cosine 0.0291082518080175
std between-class features cosine 0.2373877200066471
avg features cosine to -1/(C-1) 0.2019098455958274
features cosine for small classes [[ 1.00000000e+00  6.94912525e-03  5.24540136e-01  4.39067736e-01
   5.83946827e-01]
 [ 6.94912525e-03  1.00000000e+00  3.92964072e-01  3.31736416e-01
   4.35556675e-01]
 [ 5.24540136e-01  3.92964072e-01  1.00000000e+00 -3.27343348e-04
   5.83072993e-01]
 [ 4.39067736e-01  3.31736416e-01 -3.27343348e-04  1.00000000e+00
   5.59832488e-01]
 [ 5.83946827e-01  4.35556675e-01  5.83072993e-01  5.59832488e-01
   1.00000000e+00]]
between-calss features cosine for small classes [0.006949125251852317, 0.5245401361549198, 0.43906773605033256, 0.5839468273047944, 0.006949125251852317, 0.39296407188604654, 0.33173641579740254, 0.4355566747439725, 0.5245401361549198, 0.39296407188604654, -0.0003273433475896592, 0.5830729927125446, 0.43906773605033256, 0.33173641579740254, -0.0003273433475896592, 0.5598324876601913, 0.5839468273047944, 0.4355566747439725, 0.5830729927125446, 0.5598324876601913]
avg between-class features cosine for small classes 0.3857339124214468
std between-class features cosine for small classes 0.20703250259728517
std features norm over avg features norm for small classes 0.04407465230963954
analyze the duality of weights and features
dual distance 1.0022072446765409
dual distance square 1.004419361282144
(base) ]0;root@DESKTOP-VFHBUQ9: /mnt/e/GitHub Repo/LPMroot@DESKTOP-VFHBUQ9:/mnt/e/GitHub Repo/LPM# exist
exist: command not found
(base) ]0;root@DESKTOP-VFHBUQ9: /mnt/e/GitHub Repo/LPMroot@DESKTOP-VFHBUQ9:/mnt/e/GitHub Repo/LPM# e[Kexistsh run-mnist-collapse.sh exit[K
exit

Script done on 2021-12-13 20:45:39+0800
